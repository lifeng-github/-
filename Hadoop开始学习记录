数据存储和分析
1.读取一个磁盘中所有的数据，需要很长的时间，写甚至更慢。一个很简单的减少读取时间的办法就是从多个磁盘上读取数据。
试想，如果我们拥有100个磁盘，每个磁盘存储1%的数据，并行读取，那么不到两分钟就可以读取所有数据。

但是要解决多磁盘数据的并行读写，还要解决问题
a.需要硬件问题。一旦使用多硬件，其中任一硬件发生问题的概率很高，避免数据丢失的常见办法就是使用备份：系统保存数据的
副本，在发生故障后，可以使用的数据的另一个可用的副本。例如冗余磁盘阵列RAID就是按这个原理实现的，另外，Hadoop的文件
系统，及HDFS也是一类，不过它采取的方法稍微有不同;
b.大多数分析人物需要一某种方式结合大部分数据共同完成分析任务，即从一个磁盘读取的数据可能需要和从另外99个磁盘中读取
的数据结合使用。各种分布式系统允许结合多个来源的数据并实现分析，但保证其正确性是一个非常大的挑战，MapReduce提出一个
编程模型，改模型将上述磁盘读写的问题进行抽象，并转换为对一个数据集（有键/值对组成）的计算。

总而言之，hadoop提供了一个可靠的共享存储和分析系统。HDFS实现存储，而MapReduce实现分析处理。

2.我们为什么不使用数据库来对大量磁盘上的大规模数据进行批量分析?
a.来自磁盘的一个发展趋势：寻址时间的提高远远慢于传输速率的提高。寻址是将磁头移动到特定磁盘进行读写操作的过程。它是
导致磁盘操作延迟的主要原因，而传输速率取决于磁盘的带宽。如果数据的访问模式中包含大量的磁盘寻址，那么读取大量的数据
所花的时间势必会更长（相较于流式数据读取模式）流式读取主要取决于传输速率。另一方面，如数据库系统只更新一小部分记录，
那么传统的B树更有优势(关系型数据库中使用的一种数据结构，受限于寻址的比例).但是数据库系统更新大部分数据时，B树的效率
比MapReduce低很多，因为需要使用"排序/合并"（sort/merge）来重建数据库。

b.MapReduce视为关系型数据库管理系统的补充，两个系统的差异，就是MapReduce比较适合以批处理的方式处理需要分析整个数据集
的问题，尤其是即时分析。RDBMS适用于点查询和更新，数据集被索引后，数据库系统能够提供低延迟的数据检索和快速的少量数据
更新。MapReduce适合一次写入，多次读取数据的应用，而关系型数据库更适合持续更新的数据集。

c.MapReduce和关系数据库之间的另一个区别在于他们所操作的数据集的结构化程度。结构数据是具有既定格式的尸体数据，注入XML
文档或者满足特定约定格式的数据库表。这时RDBMS包括的内容，另一个方面，版数据化数据比较松散，虽然可能有格式，但经常被
忽略，所以它只能用作对数据结构的一般知道。例如，一张电子表格，器结构是由单元格组成的网格，但是每个单元格自身可保存任
何形式的数据。非结构化数据，没有什么特别的内部结构，例如，存文本或者图像数据。MapReduce对于非结构化或者半结构化数据
非常有效，因为在处理数据时才对数据进行解释。换句话说：MapReduce输入的键和值并不是数据固有的属性，而是有分析数据的
人员来选择。关系型数据库旺旺是规范的，以保持其数据的完整性且不含冗余。规定话给MapReduce带来了问题，因为他是记录读取成
为异地操作，然而MapReduce的核心假设之一就是，它可以进行高速的流式读写操作。如：web服务器日志是一个典型的非规范数据记录
（因为，每次都需要记录客户端主机全名，导致同一个客户端全名可能多次出现），这就是MapReduce非常适合用于分析各种日志文件
的原因之一。

d.MapReduce是一种线性可伸缩的编程模型。程序员编写两个，分别为map函数和reduce函数，每个函数定义一个键/值对集合到另一个
键/值集合的映射。这些函数无需关注数据集及其所用集群的大小，因此可以原封不动地应用到小规模数据集或大规模的数据集上。更
重要的是，如果输入的数据量是原来的两倍，那么运行的时间也需要两倍。但是如果集群是原来的两倍，作业的运行依然与原来一样快
。sql查询一般不具备改特征。

不就的将来可能关系数据库和MapReduce系统之间的差异很可能编程模糊。因为关系型数据库开始吸收MapReduce的一些思路（GreenPlum），
另一方面MapReduce的高级查询语言(如Pig和Hive)使MapReduce的提醒更接近传统的数据库编程方式。

3.网格计算，高性能计算和网格计算组织多来来一直在研究大规模数据处理，主要使用类似于消息传递接口的API，从广义上了讲，高性能
计算的方法时将作乐分散到集群的各个机器上，这些机器访问由存储区域网络（SAN）组织的共享文件系统。这个比较使用与计算密集型
的作业，但如果节点需要访问大量的数据（几百个GB的数据，这时MapReduce开始发挥其优势），那么很多计算点会由于网络带宽的瓶颈
问题而空闲下来等待数据。MapReduce会精良计算节点上的存储数据，以实现数据的本地快速访问。数据本地化特征是MapReduce的核心特征
，并因词而获得良好的性能。意思到网络带宽是数据中心环境最珍贵的资源（到处复制数据很容易耗尽网络带宽）之后，MapReduce通过
显示网络拓扑结构尽力保留网络带宽（显示网络拓扑结构？？）。注意，这种排列方式并未降低MapReduce的计算密集型的数据分析能力。

a.MPI(High performance computing)赋予程序员极大的控制能力，但是需要程序员显示控制数据流机制，包括通过C语言构造低层次的功能
模块（例如套接字）和高层次的数据分析算法。而MapReduce则更高层次上执行任务，即程序员仅从键/值对函数的角度考虑任务的执行，
这样数据流是隐含的

b.在大规模的分布式环境中，协调各进程的执行是一个很大的挑战。最困难的是很里的处理系统部分失效问题--在不知道远程进程是否已
失效的情况下同时还需要继续完成整个计算。MapReduce让程序员无需考虑系统的部分失效问题，因为自身的系统实现能够检测到失败的map
或者reduce任务，并让正常运行的机器重新执行这些失败的任务。正式由于采用了无共享框架，所以MapReduce才能够实现失败检测，这
意味着各个任务之间彼此独立。（这里讲得过于简单了一点，因为MapReduce系统本身控制着mapper的输出结果传给reducer的过程；这种
情况下，重新运行reducer比重新运行mapper更需要格外小心，因为reducer需要获取必要的mapper的输出结构，如果没有获得必要的输出
结果，必须再次运行相关mapper重新生成输出结果。）因此，从程序员角度来看，任务的执行顺序是无关紧要的。相比之下MPI程序必要显示
地管理自身的检查点和恢复机制，尽管更多的控制权交给了程序要，但也加大了编程的难度。

c.MapReduce听起来似乎是一个相当严格的编程模型，而且在某种意义上看，他的确如此：用户被限定于使用具有特定关联的键/值对，mapper
和reducer彼此间可做的协调非常有限（每个mapper将键/值对传给reducer）.由此自然会联想到一个问题：能用该编程模型做一些有用或者不同
的事情

4.Hadoop的生态圈
a.common 一组分布式文件系统和通用I/O的组件与接口(序列化，Java RPC和持久化数据结构)
b.avro  一种支持高效，跨语言的RPC以及永久存储数据的序列化系统
c.MapReduce 分布式数据处理模型和执行环境，运行与大型商用机集群
b.HDFS 分布式文件系统，运行于大型商用机集群
e.pig 一种数据流语言和运行环境，用以检索非常大的数据集。pig运行在MapReduce和HDFS的集群上
f.Hive 一个分布式，按列存储的数据仓库。Hive管理HDFS中存储的数据，并提供基于SQL的查询语言（由运行时引擎翻译成MapReduce作业）
用以查询数据。
g.HBase 一个分布式，按列存储数据库。HBase使用HDFS作为底层存储，同时支持MapReduce的批量式计算和点查询（随机读取）
h.ZooKeeper 一个分布式，可用性搞的协调服务。ZooKeeper提供分布式锁之类的基本服务用于构建分布式应用
i.Sqoop 在数据库和HDFS之间高效传输数据工具
